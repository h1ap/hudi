version: "3.8"
# version: "3.3"
# version: "2.2"

services:
  jobmanager:
    image: flink:1.14.6-scala_2.12
    ports:
      - "8081:8081"
    command: jobmanager
    volumes:
      - ./flink_libs:/opt/flink/lib
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        jobmanager.memory.process.size: 4096m
        parallelism.default: 4
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  flink_cluster_tm1:
    image: flink:1.14.6-scala_2.12
    command: taskmanager
    volumes:
      - ./flink_libs:/opt/flink/lib
    depends_on:
      - jobmanager
    environment:
      - CLUSTER_NAME=hudi_hadoop2101_flink146
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 2048m
        taskmanager.numberOfTaskSlots: 2
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  flink_cluster_tm2:
    image: flink:1.14.6-scala_2.12
    command: taskmanager
    volumes:
      - ./flink_libs:/opt/flink/lib
    depends_on:
      - jobmanager
    environment:
      - CLUSTER_NAME=hudi_hadoop2101_flink146
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 2048m
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  flink_cluster_tm3:
    image: flink:1.14.6-scala_2.12
    command: taskmanager
    volumes:
      - ./flink_libs:/opt/flink/lib
    depends_on:
      - jobmanager
    environment:
      - CLUSTER_NAME=hudi_hadoop2101_flink146
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 2048m
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  flink_cluster_tm4:
    image: flink:1.14.6-scala_2.12
    command: taskmanager
    volumes:
      - ./flink_libs:/opt/flink/lib
    depends_on:
      - jobmanager
    environment:
      - CLUSTER_NAME=hudi_hadoop2101_flink146
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.memory.process.size: 2048m
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  sql-client:
    image: flink:1.14.6-scala_2.12
    command: bin/sql-client.sh
    volumes:
      - ./flink_libs:/opt/flink/lib
    depends_on:
      - jobmanager
    environment:
      - CLUSTER_NAME=hudi_hadoop2101_flink146
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        parallelism.default: 1
        state.backend: rocksdb
        state.checkpoints.dir: hdfs://namenode:8020/flink-checkpoints
        state.savepoints.dir: hdfs://namenode:8020/flink-savepoints
        state.backend.incremental: true
        execution.checkpointing.interval: 60000
        taskmanager.network.blocking-shuffle.type: mmap
        taskmanager.network.blocking-shuffle.compression.enabled: true
        jobmanager.archive.fs.dir: hdfs://namenode:8020/completed-jobs
        cluster.evenly-spread-out-slots: true
        heartbeat.timeout: 180000
        akka.framesize: 251658240b
        classloader.check-leaked-classloader: false

  namenode:
    image: heap/hudi-hadoop_2.10.1-namenode:latest
    hostname: namenode
    container_name: namenode
    environment:
      HDFS_USER: flink
      CLUSTER_NAME: hudi_hadoop2101_flink146
    ports:
      - "8020:8020"
      - "8088:8088"
      - "9870:9870"
      - "14000:14000"
      - "50070:50070"
      - "50075:50075"
      - "10020:10020"
      - "13562:13562"
      - "19888:19888"
      - "5004"
    env_file:
      - ./hadoop.env
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://namenode:50070" ]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode1:
    image: heap/hudi-hadoop_2.10.1-datanode:latest
    container_name: datanode1
    hostname: datanode1
    deploy:
      resources:
        limits:
          cpus: "1.00"
          memory: 512M
        reservations:
          memory: 128M
    environment:
      HDFS_USER: flink
      CLUSTER_NAME: hudi_hadoop2101_flink146
    env_file:
      - ./hadoop.env
    ports:
      - "50076:50075"
      - "50010:50010"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    links:
      - "namenode"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://datanode1:50075" ]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - namenode
        
  datanode2:
    image: heap/hudi-hadoop_2.10.1-datanode:latest
    container_name: datanode2
    hostname: datanode2
    deploy:
      resources:
        limits:
          cpus: "1.00"
          memory: 512M
        reservations:
          memory: 128M
    environment:
      HDFS_USER: flink
      CLUSTER_NAME: hudi_hadoop2101_flink146
    env_file:
      - ./hadoop.env
    ports:
      - "50077:50075"
      - "50011:50010"
      # JVM debugging port (will be mapped to a random port on host)
      - "5006"
    links:
      - "namenode"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://datanode2:50075" ]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - namenode
        
  datanode3:
    image: heap/hudi-hadoop_2.10.1-datanode:latest
    container_name: datanode3
    hostname: datanode3
    deploy:
      resources:
        limits:
          cpus: "1.00"
          memory: 512M
        reservations:
          memory: 128M
    environment:
      HDFS_USER: flink
      CLUSTER_NAME: hudi_hadoop2101_flink146
    env_file:
      - ./hadoop.env
    ports:
      - "50078:50075"
      - "50012:50010"
      # JVM debugging port (will be mapped to a random port on host)
      - "5007"
    links:
      - "namenode"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://datanode3:50075" ]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - namenode

volumes:
  namenode:

networks:
  default:
